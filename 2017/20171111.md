# 11 November 2017

# Parsing

"lexeme": the atomic unit of a language. `var`, `=`, and `foo` are lexemes 
in JavaScript.

Various kinds of lexemes:

- Single character
- One or two character
- Literals
- Keywords
- End of file (EOF)

During the scanning stage, the scanner wraps the lexeme in a token.
Whereas a lexeme is a raw substring of the source code, the token is a data
structure representing the lexeme.

Tokens are identified by unique types.

Example:

```javascript
const TokenTypes = {
  LEFT_PAREN: 'LEFT_PAREN',
  RIGHT_PAREN: 'RIGHT_PAREN',
  BANG: 'BANG',
  BANG_EQUAL: 'BANG_EQUAL',

  ...
}
```

A token can contain:

- Type
- Lexeme: raw source string
- Literal value: when the lexeme is a value, this is a conversion of that value
  to an equivalent value the source code will use later. e.g. `"4"` to `4`.
- Location: line, col, etc.

### Grammar

A "lexical grammar" is the set of rules that maps character patterns to lexemes.

#### Regular grammar

A typical lexer is based on first-match, longest-match regular expressions.
A regular expression describes a regular language.

A regular grammar is a formal grammar that is right-regular or left-regular.
Right-regular and left-regular grammars are linear grammars.
A linear grammar is a context-free grammar that has at _most one nonterminal_ in
the right hand side of its productions.
Right-regular: all nonterminals in right hand side are on right ends: `B -> aC`.
Left-regular: all nonterminals in right hand side are on left ends: `B -> Ca`.

**Example**

The regular expression `a*bc*` describes a regular language where there is 0
or more a's followed by 1 b followed by 0 or more c's. "abc" is in that language.
So is "b" and "aabcc". "abbc" is *not* in that language.

That language is described by this right regular grammar:

```
Start -> A
A -> aA
A -> B
B -> bC
C -> cC
C -> Empty
```

Regular languages are recognized by a finite automaton.

All finite languages are regular. A language where the terminal can occur
zero or more times is not regular because it is not finite. 

_Why aren't the lexical grammars of Python and Haskell regular?_

>Haskell, like Python, uses indentation to indicate grammatical structure, so 
>we should expect that it requires context-sensitive parsing.

An example of context-sensitive parsing:

```python
for i in x:
  for j in y:
    print j
  print i
```

The indentation is significant, so the parsing of each token must be aware of
that token's context.

**Further reading**

- [StackOverflow: What does finite mean in the context of Kleene stars and regular languages?](https://stackoverflow.com/questions/47239506/what-does-finite-mean-in-the-context-of-kleene-stars-and-regular-languages)
- [Python is not context free](http://trevorjim.com/python-is-not-context-free/)
- [Haskell is not context free](http://trevorjim.com/python-is-not-context-free/)

_What is the significance of whitespace in CoffeeScript, Ruby, and C?_

_Why are nested comments hard to parse?_

_Do parser combinators combine the scanning and parsing steps?_

_It seems like the parser combinator approach combines the scanning step and_
